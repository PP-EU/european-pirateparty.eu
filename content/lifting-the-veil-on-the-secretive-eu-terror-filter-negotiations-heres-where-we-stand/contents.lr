title: LIFTING THE VEIL ON THE SECRETIVE EU TERROR FILTER NEGOTIATIONS: HERE’S WHERE WE STAND
---
type: post
---
tags: 
 
censorship
default
terreg
internet_censorhip
articles

---
pub_date: 2020-03-30
---
img: /logo_european_pirate_party.png
---
description: Next week (18 March – update: postponed) the fourth **“Trilogue” meeting**
will be held on the EU’s proposed terrorist content online law infamous for
its “upload filter”/”preventive measures” and “one hour removal orders”
provisions. Trilogue means: In a series of **closed-door meetings** , the
European Parliament and the Council (representing the member state
governments), supported by the Commission, hammer out a final text acceptable
to both institutions. It’s the last chance to make changes before the
regulation gets adopted. In my **[previous blog post](https://www.patrick-
breyer.de/?p=589500&lang=en)** I have published the timetable of negotiations
as well as the negotiators and external documents for further reading,
including by the[
F](https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-opinion-
online-terrorism-regulation-02-2019_en.pdf)[undamental
](https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-opinion-
online-terrorism-
regulation-02-2019_en.pdf)[R](https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-opinion-
online-terrorism-regulation-02-2019_en.pdf)[ights
Agency](https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-opinion-
online-terrorism-regulation-02-2019_en.pdf), three [UN Special
Rapporteurs](https://spcommreports.ohchr.org/TMResultsBase/DownLoadPublicCommunicationFile?gId=24234),
[Digitaleurope](https://www.digitaleurope.org/wp/wp-
content/uploads/2019/10/DIGITALEUROPE-Views-on-Terrorist-Content-Online-
Regulation-October-2019.pdf), [Global Networks
Initiative](https://globalnetworkinitiative.org/wp-
content/uploads/2019/01/GNI-Statement-Proposed-EU-Regulation-on-Terrorist-
Content.pdf)and [Internet pioneers](https://www.politico.eu/wp-
content/uploads/2019/04/TCO-letter-to-rapporteurs.pdf). Last Friday a [“4
column document” was leaked](https://www.politico.eu/wp-
content/uploads/2020/03/SKM_C45820030612100.pdf) which reveals a **compromise
proposed by the European Parliament** ‘s lead negotiator (rapporteur).
Negotiations are **nearing the end**. Every meeting is more decisive than the
previous one. Therefore, every minor change could be crucial. Below, you can
see the different positions of the Parliament, Commission and Council and what
how these would affect everyone, from internet users to SMEs and other online
enterprises
---
body: .

## Video

[![Video](https://www.patrick-breyer.de/wp-
content/uploads/2020/03/terreg_en-1024x576.jpg)](https://www.invidio.us/watch?v=AzMTkVB8wqw)Video:
Interview on the proposed regulation (external link)

## Council and Parliament positions

Let’s begin by taking a close look at the similarities and differences of the
Council and Parliament positions (as proposed now), and break down what they
would mean for you:  **Commission and Council want** | **Parliament wants** |
**What this means for you**  
---|---|---  
  
  * The proposed regulation shall **apply to anybody who is making available information** online at the request of a user

|

  * The proposed regulation shall apply to anybody who is **publishing** information at the request of a user, **except for “closed user groups consisting of a finite number of pre-determined people”, communications services** (e.g. messengers) **and cloud infrastructure providers**

| If you operate a website users can contribute to (e.g. a wordpress blog with
comments function or a wiki) you would have to satisfy removal orders within
one hour, even at night, and possibly implement upload filters. Trolls could
provoke authorities to act against you by repeatedly posting terrorist content
on your website.  
  
  * Hosting service providers shall **remove content within 1 hour** of receiving a removal order

|

  * Hosting service providers shall remove content within 1 hour of receiving a removal order **except in cases of “de facto impossibility** not attributable to the hosting service provider, including for technical reasons”; 12-hour advance warning for the first order

| Individuals or small organisations may decide to terminate services and
platforms rather than stand ready 24/7 to respond within one hour to a removal
order that will never be issued, because 99%+ of platforms are never targeted
with terrorist propaganda. The exception proposed by the European Parliament
is too narrow and lacks the legal certainty to protect small businesses, non-
profit organizations and individuals operating websites.  
  
  * Removal of terrorist content can be ordered even if disseminated for **educational, artistic, journalistic or research purposes** , or for awareness raising purposes against terrorist activity

|

  * **Protect and preserve** content disseminated for educational, artistic, journalistic or research purposes, or for awareness raising purposes against terrorist activity

| Some media reports on terrorist activities could be removed if the
Commission’s proposal goes through. Video archives that document war crimes,
for example in Syria, will partially disappear, resulting in impunity of
perpetrators. Spain has prosecuted artists for satirical performances in the
past, so recordings of performances could be deleted in the future.  
  
  * Member states can freely decide **which authority** may order content take-downs

|

  * National authorities shall not seek or take instructions from any other body when making orders

| Where no requirement of independence is in place, ministers could directly
order the removal of content for political reasons. The European Parliament’s
proposal does not prevent the government from designating a Ministry to be
able to directly order content take-downs.  
  
  * The authority of any one EU Member state can order the **removal of content in any other EU Member state** (cross-border removal orders)

|

  * Member state authorities can have content removed by hosting service providers located in their own country and request providers in other Member States to remove content

| If Commission and Council have their way, content you wish to access could
have been removed due to orders from Member States with populist,
authoritarian governments. For example, Hungary has been found in the past to
disrespect the rule of law. Hungary has called environmental activists
“ecoterrorists”. Spain is using anti-terrorism laws against the Catalan
independence movement. France has also been reported to excessively request
content removals abroad.  
  
  * EU authorities can order content removals with a **global effect** (e.g. order a US provider to remove content with effect for US citzens)

|

  * Service providers can satisfy removal orders by disabling access to content **“in all Member States” (in the EU)** , without having to delete content altogether

| Removing content globally could result in other states such as Turkey,
Russia, Saudi Arabia or China requiring the removal content which, in Europe,
is perfectly legal and legitimate.  
  
  * Hosting service providers shall decide with priority on whether or not to take down content due to a violation of their terms of service upon receiving a “ **referral** ” from a national authority

|

  * National authorities shall only report actual terrorist content as defined by the relevant legislation

| Referrals would result in the removal of content that is perfectly legal and
merely violates the arbitrary rules set by a private hosting service provider.  
  
  * Hosting service providers shall include in their **terms and conditions** that they will not store terrorist content (Council)

|

  * Hosting service providers shall include in their terms and conditions **provisions to address the misuse of their service for the dissemination** of terrorist content

| Terrorist content should be a matter of public policy, not of terms and
conditions. Private policing/enforcement by the tech industry is not
democratically legitimised, lacks independence, is intransparent and not
controlled by the judiciary. This burdens small operators, since many of them
do not even use terms and conditions. Where website operators use identical
terms and conditions worldwide, forcing modifications could have a global
effect far beyond the EU. Would we want Chinese or Turkish requirements in
terms and services applicable to our citizens?  
  
  * Hosting service providers shall use “ **proactive measures** ” to **prevent** the re-upload of content previously taken down and to **detect** and **identify** alleged terrorist content

|

  * Hosting service providers shall not be required to use automated tools (such as “upload filters”)

| Automated upload filters are censorship machines that have been proven to
suppress completely legal content (e.g. documentation of human rights
violations in civil wars). Even a filter with an extremely high accuracy rate
close to 99% would delete more legal content than illegal content, because
terrorist material is extremely rare compared to the overall number of
uploads. Even for identical content (e.g. an image) the classification as
illegal “terrorist content” depends on the publisher’s intention (e.g. media
coverage, awareness raising, terrorist research, criticizing terrorism).
Automated tools can never assess the context and intention of a publication.
The [GIFCT re-upload filters currently in use](https://gifct.org/) are
intransparent and lacking public control. If service providers were obliged to
use automated tools for flagging content, the amount of reported content would
be so high that providers would “voluntarily” block all such content without a
proper assessment.  
* * * 

## Article 6: Upload filters / “Proactive measures”

Although mandatory upload filters have already been imposed in the context of
the **controversial copyright reform (Article 13)** , the European Court of
Justice is reviewing the provision and may yet strike it down for legal
unclarity. With the proposed “terrorist content” law and the future “Digital
Services Act” however, **mandatory upload filtering may become a standard
requirement** for the Internet. Upload filters are **ineffective**. They would
not be applied by non-EU platforms hosting terrorist content such as 4chan,
8chan and Gab. And they are easy to circumvent on other platforms. For
instance, Facebook has over 800 slightly modified duplicates of the
Christchurch shooting video in its hash-sharing database. Upload filters are
prone to **systematically produce false positives** and result in accidentally
suppressing legal content (overblocking). Since algorithms cannot account for
contextual interpretation of the legal (re-)use of the content, legal uses of
terrorist material would be prevented (such as for educational, artistic,
journalistic or research purposes, or for awareness raising purposes against
terrorist activity, for expressing polemic or controversial views in the
course of public debate). For example the Syrian Archive is documenting war
crimes committed by terrorist organisations on Youtube but has had a great
part of its documentation deleted. The same could go for media reports on
terrorist attacks. **Complaints procedures** or subsequent judicial review
procedures are insufficient to tackle the risks of automatic filtering. In
practise affected users and companies will hardly ever invest time and money
into a complicated – possibly international – procedure of challenge a removal
order. Also subsequent judicial review takes too long to protect legal speech
on current affairs. When content is eventually reinstated your message will no
longer be relevant. In the context of the copyright reform we have seen
**hundreds of thousands of young people in the streets** protesting against
Internet censorship. Yet Commission and national governments seek to make
compulsory upload filters a general rule, ignoring public protest as if
nothing had happened.

### What this means for you:

  * **Error-prone upload filters** will need to approve everything you want to post or upload to platforms like Instagram, YouTube, Snapchat, Facebook, Tumblr, WordPress.org, Wattpad, DeviantArt, SoundCloud, TikTok, Giphy etc. before it can appear online. This will mean **delays and mistakes**. Upload filters will consider you “guilty until proven innocent”, guaranteeing that perfectly legal contributions will be withheld – especially criticism and journalistic reporting on terrorist content.
  * **Services you rely on** will start geoblocking the EU if they can’t handle the liability.

### What this means for all of us:

  * **Freedom of expression would be limited** as the internet turns from a place where contributions are welcome to one where they first need to pass automated scrutiny. Do we want intransparent algorithms to decide on what we can say and read?
  * **Media coverage, education, arts, research, awareness raising and controversial debates on terrorism** will suffer.
  * The **censorship infrastructure** established this way is sure to be expanded to other types of content. Once introduced for terrorist content the upcoming Digital Services Act is likely to make upload filters compulsory to look for any illegal material.
  * **Innovation killed:** This law guarantees there will never be a European alternative to the big social networks and sharing sites. The few US giants able to invest the giant sums required into upload filters will license them out to others and find their market dominance fortified.

* * * 

## Article 4: Ultra-fast cross-border removal orders

According to the proposed regulation service providers shall **remove content
within 1 hour** of receiving a removal order. Excessive requirements endanger
the freedom of expression, journalistic reporting, science, arts and culture,
but also the digital economy. Satisfying content removal orders **within one
hour** , even at night or on week-ends, is impossible for many operators of
Internet services to do. The exception proposed by the European Parliament by
way of compromise is too narrow and lacks the legal certainty to protect small
businesses, non-profit organizations and individuals operating websites.
Furthermore there is **no consensus in the EU on what constitutes a “terrorist
group”** , for example on Catalonian separatists, Kurds, Palestinians etc.
Every Member State can take their own decision. Hungary has in the past been
labeling environmental activists “ecoterrorists”, France has used anti-terror
legislation on social protesters. If any EU country can request the
suppression of content in another, this would affect content that is perfectly
legal in the hosting country, and would result in a race to the bottom on
freedom of expression. Take-down orders that do not require a judicial order
could be **used for political purposes** by “law and order” politicians.

### What this means for you:

  * Individuals or small organisations may decide to **terminate services and platforms** rather than stand ready 24/7 to respond within one hour to a removal order.

### What this means for all of us:

  * **Freedom of expression would be limited** as “law and order” politicians have political content taken down by labelling it “terrorist”, even if hosted in a country where it is perfectly legal.
  * **Media coverage, education, arts, research, awareness raising and controversial debates on terrorism** will suffer.
  * **Innovation killed:** This law harms small European Internet businesses. The few US giants able to react within one hour will find their market dominance fortified.

* * * 

## What you can do

Do you fear that this law will cause **massive damage** to a free and open
internet and that its benefits do not outweigh this damage? If **EU
governments in Council continue to insist on ever further-reaching content
removal provisions and mandatory automated filtering (upload filters)** of
online content, there is a risk that it could become more important to a
majority of your representatives in the European Parliament to be seen to do
“something” about terrorist content online than insist on the respect for
fundamental rights, free speech and protecting the Internet community. Our
best bet right now is to **increase pressure on the governments** represented
in Council. Contact the [government’s permanent
representations](https://op.europa.eu/en/web/who-is-
who/organization/-/organization/REPRES_PERM/REPRES_PERM) or the Ministries of
the interior. **Help keep up public attention** throughout the trilogues:
Reach out to local media, comment on the progress of the negotiations, make
videos, share my posts, keep your friends informed. Nothing is set in stone
just yet – but we need to step it up to stop excessive content removal
requirements and mandatory upload filters.

## More information

  1. [Negoziati sul sistema dell’UE per il filtraggio dei contenuti terroristici: la situazione attuale [aggiornata al 07 febbraio 2020] ](https://www.patrick-breyer.de/?p=590406&lang=en "Negoziati sul sistema dell’UE per il filtraggio dei contenuti terroristici: la situazione attuale \[aggiornata al 07 febbraio 2020\]")
  2. [Négociations d’un système de filtrage de contenus à caractère terroriste ](https://www.patrick-breyer.de/?p=590403&lang=en "Négociations d’un système de filtrage de contenus à caractère terroriste")
  3. [Pregovori o filterima EU-a za terorističke sadržaje: trenutačno stanje [ažurirano 07. veljača 2020] ](https://www.patrick-breyer.de/?p=590404&lang=en "Pregovori o filterima EU-a za terorističke sadržaje: trenutačno stanje \[ažurirano 07. veljača 2020\]")
  4. [Las negociaciones sobre el filtrado de contenidos terroristas en la UE: situación actual [actualizado el 07 de febrero de 2020] ](https://www.patrick-breyer.de/?p=590402&lang=en "Las negociaciones sobre el filtrado de contenidos terroristas en la UE: situación actual \[actualizado el 07 de febrero de 2020\]")
  5. [Fighting Terrorism propaganda online: Excluding the wrong players](https://www.patrick-breyer.de/?p=590363&lang=en "Fighting Terrorism propaganda online: Excluding the wrong players")

